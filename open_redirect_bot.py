#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import sys
import types
import logging
import traceback
import asyncio
import urllib.parse
import os
import requests
import time
import random
import re
import json
from urllib.parse import urlparse, quote_plus
from concurrent.futures import ThreadPoolExecutor, as_completed
from threading import Lock

# ===================== –ù–ê–°–¢–†–û–ô–ö–ê –õ–û–ì–û–í (–í–ê–ñ–ù–û!) =====================
logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    level=logging.INFO,
    stream=sys.stdout,
    force=True
)
sys.stdout.reconfigure(line_buffering=True)

# –ì–ª–æ–±–∞–ª—å–Ω—ã–π –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ –æ—à–∏–±–æ–∫
def global_exception_handler(exctype, value, tb):
    logging.critical("üî• –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê:", exc_info=(exctype, value, tb))
    sys.stdout.flush()
    sys.exit(1)

sys.excepthook = global_exception_handler

# ===================== –ó–ê–ì–õ–£–®–ö–ê –î–õ–Ø imghdr =====================
imghdr = types.ModuleType('imghdr')
def what(*args, **kwargs):
    return None
imghdr.what = what
sys.modules['imghdr'] = imghdr

# ===================== –ò–ú–ü–û–†–¢–´ –ë–ò–ë–õ–ò–û–¢–ï–ö TELEGRAM =====================
from telegram import Update
from telegram.constants import ParseMode
from telegram.ext import Application, CommandHandler, MessageHandler, CallbackContext
from telegram.ext import filters

# ===================== –ù–ê–°–¢–†–û–ô–ö–ò =====================
TOKEN = "8618230715:AAF30AK5Nef4KnLuILUXu7GKpKO4TLrHWYc"

USER_AGENTS = [
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36",
    "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36",
    "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36"
]

REDIRECT_PARAMS = [
    "redirect", "url", "next", "return", "returnTo", "return_to",
    "continue", "dest", "destination", "redir", "redirect_uri",
    "redirect_url", "goto", "target", "r", "u", "link", "to"
]

TEST_PAYLOAD = "https://example.com"

PAYLOADS = [
    TEST_PAYLOAD,
    f"//example.com",
    f"http://example.com",
    f"https:example.com",
    f"/\\example.com",
    f"https://example.com%2F%2E%2E",
    f"%2F%2Fexample.com",
    f"///example.com",
    f"https://example.com/?a=1&b=2",
    f"https://example.com#test",
]

user_sessions = {}
sessions_lock = Lock()
logger = logging.getLogger(__name__)

# ===================== –§–£–ù–ö–¶–ò–ò –ü–û–ò–°–ö–ê =====================

def search_domains_google(query="site:.com", max_pages=1):
    """–ò—â–µ—Ç –¥–æ–º–µ–Ω—ã —á–µ—Ä–µ–∑ Google (–æ–±—Ö–æ–¥ –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏)"""
    domains = set()
    
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∑–∞–≥–æ–ª–æ–≤–∫–∏ —Ä–µ–∞–ª—å–Ω–æ–≥–æ –±—Ä–∞—É–∑–µ—Ä–∞
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
        "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8",
        "Accept-Language": "en-US,en;q=0.5",
        "Accept-Encoding": "gzip, deflate, br",
        "DNT": "1",
        "Connection": "keep-alive",
        "Upgrade-Insecure-Requests": "1"
    }
    
    # –ö–æ–¥–∏—Ä—É–µ–º –∑–∞–ø—Ä–æ—Å –¥–ª—è URL
    import urllib.parse
    encoded_query = urllib.parse.quote_plus(query)
    
    for page in range(max_pages):
        start = page * 10
        url = f"https://www.google.com/search?q={encoded_query}&start={start}"
        
        try:
            print(f"[*] –ó–∞–ø—Ä–æ—Å –∫ Google: {url[:100]}...")
            sys.stdout.flush()
            
            # –î–æ–±–∞–≤–ª—è–µ–º —Ç–∞–π–º–∞—É—Ç –∏ –∑–∞–ø—Ä–µ—â–∞–µ–º —Ä–µ–¥–∏—Ä–µ–∫—Ç—ã
            r = requests.get(
                url, 
                headers=headers, 
                timeout=15,
                allow_redirects=True
            )
            
            print(f"[*] –°—Ç–∞—Ç—É—Å –æ—Ç–≤–µ—Ç–∞: {r.status_code}")
            sys.stdout.flush()
            
            if r.status_code == 200:
                # –ò—â–µ–º –≤—Å–µ —Å—Å—ã–ª–∫–∏
                found = re.findall(r'https?://([^/\s"\']+)', r.text)
                
                for domain in found:
                    # –ß–∏—Å—Ç–∏–º –¥–æ–º–µ–Ω
                    domain = domain.split('/')[0].split('?')[0].split('#')[0]
                    
                    # –û—Ç—Å–µ–∏–≤–∞–µ–º –º—É—Å–æ—Ä
                    if ('.' in domain 
                        and not any(x in domain for x in [
                            'google', 'youtube', 'blogger', 'gstatic',
                            'googleapis', 'ytimg', 'ggpht'
                        ])
                        and len(domain) < 50):
                        domains.add(domain)
                
                print(f"[*] –ù–∞–π–¥–µ–Ω–æ –¥–æ–º–µ–Ω–æ–≤ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ {page+1}: {len(found)}")
                sys.stdout.flush()
            else:
                print(f"[!] Google –≤–µ—Ä–Ω—É–ª —Å—Ç–∞—Ç—É—Å {r.status_code}")
                sys.stdout.flush()
            
            # –ñ–¥—ë–º –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
            time.sleep(random.uniform(3, 5))
            
        except Exception as e:
            print(f"[!] –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ: {e}")
            sys.stdout.flush()
            continue
    
    # –ï—Å–ª–∏ –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞—à–ª–∏ —á–µ—Ä–µ–∑ –ø—Ä—è–º–æ–π –∑–∞–ø—Ä–æ—Å, –∏—Å–ø–æ–ª—å–∑—É–µ–º –∑–∞–ø–∞—Å–Ω–æ–π –≤–∞—Ä–∏–∞–Ω—Ç
    if not domains:
        print("[*] –ü—Ä–æ–±—É—é –∑–∞–ø–∞—Å–Ω–æ–π –≤–∞—Ä–∏–∞–Ω—Ç...")
        sys.stdout.flush()
        
        # –ü—Ä–æ–±—É–µ–º —á–µ—Ä–µ–∑ startpage.com (–Ω–µ –±–ª–æ–∫–∏—Ä—É–µ—Ç)
        try:
            sp_url = f"https://www.startpage.com/sp/search?query={encoded_query}"
            r = requests.get(sp_url, headers=headers, timeout=15)
            
            if r.status_code == 200:
                found = re.findall(r'https?://([^/\s"\']+)', r.text)
                for domain in found:
                    domain = domain.split('/')[0].split('?')[0].split('#')[0]
                    if '.' in domain and not any(x in domain for x in ['startpage', 'google']):
                        domains.add(domain)
        except Exception as e:
            print(f"[!] –ó–∞–ø–∞—Å–Ω–æ–π –≤–∞—Ä–∏–∞–Ω—Ç —Ç–æ–∂–µ –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª: {e}")
            sys.stdout.flush()
    
    return list(domains)

# ===================== –§–£–ù–ö–¶–ò–ò –°–ö–ê–ù–ò–†–û–í–ê–ù–ò–Ø =====================

def check_open_redirect(url, param, payload):
    if '?' in url:
        separator = '&'
    else:
        separator = '?'
    
    test_url = f"{url}{separator}{param}={payload}"
    headers = {"User-Agent": random.choice(USER_AGENTS)}
    
    try:
        r = requests.get(test_url, headers=headers, timeout=8, allow_redirects=False)
        
        if 'Location' in r.headers:
            location = r.headers['Location']
            if 'example.com' in location or payload.replace('https://', '').replace('http://', '') in location:
                return {
                    "vulnerable": True,
                    "url": test_url,
                    "param": param,
                    "payload": payload,
                    "location": location,
                    "status": r.status_code
                }
        
        if 300 <= r.status_code < 400 and 'example.com' in r.text.lower():
            return {
                "vulnerable": True,
                "url": test_url,
                "param": param,
                "payload": payload,
                "status": r.status_code,
                "type": "meta/html"
            }
        
        return None
    except Exception as e:
        logger.debug(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ {test_url}: {e}")
        return None

def scan_single_url(url):
    results = []
    for param in REDIRECT_PARAMS:
        for payload in PAYLOADS:
            result = check_open_redirect(url, param, payload)
            if result:
                results.append(result)
    return results

def scan_urls(urls, max_workers=5, progress_callback=None):
    all_results = {}
    total = len(urls)
    completed = 0
    
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        future_to_url = {executor.submit(scan_single_url, url): url for url in urls}
        
        for future in as_completed(future_to_url):
            url = future_to_url[future]
            completed += 1
            if progress_callback:
                progress_callback(completed, total)
            
            try:
                results = future.result()
                if results:
                    all_results[url] = results
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–∏ {url}: {e}")
                continue
    
    return all_results

# ===================== –û–ë–†–ê–ë–û–¢–ß–ò–ö–ò –ö–û–ú–ê–ù–î =====================

async def start(update: Update, context: CallbackContext):
    user = update.effective_user
    await update.message.reply_text(
        f"–ü—Ä–∏–≤–µ—Ç, {user.first_name}!\n\n"
        "–Ø –±–æ—Ç –¥–ª—è –ø–æ–∏—Å–∫–∞ Open Redirect —É—è–∑–≤–∏–º–æ—Å—Ç–µ–π.\n\n"
        "–ö–æ–º–∞–Ω–¥—ã:\n"
        "/search - –ù–∞–π—Ç–∏ –¥–æ–º–µ–Ω—ã –∏ –ø—Ä–æ—Å–∫–∞–Ω–∏—Ä–æ–≤–∞—Ç—å\n"
        "/scanurl - –°–∫–∞–Ω–∏—Ä–æ–≤–∞—Ç—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π URL\n"
        "/scanlist - –°–∫–∞–Ω–∏—Ä–æ–≤–∞—Ç—å —Å–ø–∏—Å–æ–∫ URL –∏–∑ —Ñ–∞–π–ª–∞\n"
        "/help - –ü–æ–¥—Ä–æ–±–Ω–∞—è –ø–æ–º–æ—â—å"
    )

async def help_command(update: Update, context: CallbackContext):
    help_text = """
*Open Redirect Bot - –ü–æ–º–æ—â—å*

/search - –ù–∞–π—Ç–∏ –¥–æ–º–µ–Ω—ã –∏ –ø—Ä–æ—Å–∫–∞–Ω–∏—Ä–æ–≤–∞—Ç—å
/scanurl - –°–∫–∞–Ω–∏—Ä–æ–≤–∞—Ç—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π URL
/scanlist - –°–∫–∞–Ω–∏—Ä–æ–≤–∞—Ç—å —Å–ø–∏—Å–æ–∫ URL –∏–∑ —Ñ–∞–π–ª–∞
"""
    await update.message.reply_text(help_text, parse_mode=ParseMode.MARKDOWN)

async def search_command(update: Update, context: CallbackContext):
    user_id = update.effective_user.id
    
    with sessions_lock:
        user_sessions[user_id] = {
            'state': 'awaiting_search_query',
            'data': {}
        }
    
    await update.message.reply_text(
        "–í–≤–µ–¥–∏—Ç–µ –ø–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å –¥–ª—è Google\n"
        "–ò–ª–∏ –æ—Ç–ø—Ä–∞–≤—å—Ç–µ 'default' –¥–ª—è –ø–æ–∏—Å–∫–∞ site:.com"
    )

async def scanurl_command(update: Update, context: CallbackContext):
    user_id = update.effective_user.id
    
    with sessions_lock:
        user_sessions[user_id] = {
            'state': 'awaiting_url',
            'data': {}
        }
    
    await update.message.reply_text(
        "–û—Ç–ø—Ä–∞–≤—å—Ç–µ URL –¥–ª—è —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è"
    )

async def scanlist_command(update: Update, context: CallbackContext):
    user_id = update.effective_user.id
    
    with sessions_lock:
        user_sessions[user_id] = {
            'state': 'awaiting_file',
            'data': {}
        }
    
    await update.message.reply_text(
        "–û—Ç–ø—Ä–∞–≤—å—Ç–µ —Ç–µ–∫—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª —Å URL (–ø–æ –æ–¥–Ω–æ–º—É –Ω–∞ —Å—Ç—Ä–æ–∫—É)"
    )

async def handle_message(update: Update, context: CallbackContext):
    user_id = update.effective_user.id
    text = update.message.text
    
    with sessions_lock:
        session = user_sessions.get(user_id)
        if not session:
            await update.message.reply_text("–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ /start")
            return
    
    state = session.get('state')
    
    if state == 'awaiting_search_query':
        query = text if text != 'default' else 'site:.com'
        
        await update.message.reply_text(f"üîç –ò—â—É –¥–æ–º–µ–Ω—ã...")
        
        try:
            domains = search_domains_google(query, max_pages=2)
            
            if not domains:
                await update.message.reply_text("‚ùå –î–æ–º–µ–Ω—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
                return
            
            urls = []
            for domain in domains[:20]:
                urls.extend(generate_urls_from_domain(domain))
            
            await update.message.reply_text(f"üîç –°–∫–∞–Ω–∏—Ä—É—é {len(urls)} URL...")
            
            def progress(current, total):
                if current % 50 == 0:
                    context.application.create_task(
                        update.message.reply_text(f"–ü—Ä–æ–≥—Ä–µ—Å—Å: {current}/{total}")
                    )
            
            results = scan_urls(urls, max_workers=5, progress_callback=progress)
            
            if results:
                msg = f"‚úÖ –ù–∞–π–¥–µ–Ω–æ —É—è–∑–≤–∏–º–æ—Å—Ç–µ–π –Ω–∞ {len(results)} URL"
                await update.message.reply_text(msg)
                
                filename = f"results_{user_id}.txt"
                with open(filename, 'w') as f:
                    for url, vulns in results.items():
                        f.write(f"\n[VULN] {url}\n")
                        for v in vulns:
                            f.write(f"  {v['param']}\n")
                
                with open(filename, 'rb') as f:
                    await update.message.reply_document(f)
                
                os.remove(filename)
            else:
                await update.message.reply_text("‚ùå –£—è–∑–≤–∏–º–æ—Å—Ç–µ–π –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
            
        except Exception as e:
            await update.message.reply_text(f"‚ùå –û—à–∏–±–∫–∞: {str(e)}")
            logger.error(f"–û—à–∏–±–∫–∞: {e}", exc_info=True)
        
        with sessions_lock:
            del user_sessions[user_id]
    
    elif state == 'awaiting_url':
        url = text
        if not url.startswith(('http://', 'https://')):
            url = 'https://' + url
        
        await update.message.reply_text(f"üîç –°–∫–∞–Ω–∏—Ä—É—é...")
        
        try:
            results = scan_single_url(url)
            
            if results:
                msg = f"‚úÖ –ù–∞–π–¥–µ–Ω–æ —É—è–∑–≤–∏–º–æ—Å—Ç–µ–π: {len(results)}"
                await update.message.reply_text(msg)
            else:
                await update.message.reply_text("‚ùå –£—è–∑–≤–∏–º–æ—Å—Ç–µ–π –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
            
        except Exception as e:
            await update.message.reply_text(f"‚ùå –û—à–∏–±–∫–∞: {str(e)}")
        
        with sessions_lock:
            del user_sessions[user_id]

async def handle_file(update: Update, context: CallbackContext):
    user_id = update.effective_user.id
    
    with sessions_lock:
        session = user_sessions.get(user_id)
        if not session or session.get('state') != 'awaiting_file':
            await update.message.reply_text("–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ /scanlist")
            return
    
    file = update.message.document
    if not file.file_name.endswith('.txt'):
        await update.message.reply_text("‚ùå –ù—É–∂–µ–Ω .txt —Ñ–∞–π–ª")
        return
    
    await update.message.reply_text("üì• –ó–∞–≥—Ä—É–∂–∞—é...")
    
    file_obj = await file.get_file()
    filename = f"upload_{user_id}.txt"
    await file_obj.download_to_drive(filename)
    
    try:
        with open(filename, 'r') as f:
            urls = [line.strip() for line in f if line.strip()]
        
        if not urls:
            await update.message.reply_text("‚ùå –§–∞–π–ª –ø—É—Å—Ç")
            return
        
        urls = [u if u.startswith(('http://', 'https://')) else 'https://' + u for u in urls]
        
        await update.message.reply_text(f"üîç –°–∫–∞–Ω–∏—Ä—É—é {len(urls)} URL...")
        
        def progress(current, total):
            if current % 20 == 0:
                context.application.create_task(
                    update.message.reply_text(f"–ü—Ä–æ–≥—Ä–µ—Å—Å: {current}/{total}")
                )
        
        results = scan_urls(urls, max_workers=5, progress_callback=progress)
        
        if results:
            msg = f"‚úÖ –ù–∞–π–¥–µ–Ω–æ —É—è–∑–≤–∏–º–æ—Å—Ç–µ–π –Ω–∞ {len(results)} URL"
            await update.message.reply_text(msg)
            
            results_filename = f"results_{user_id}.txt"
            with open(results_filename, 'w') as f:
                for url, vulns in results.items():
                    f.write(f"\n[VULN] {url}\n")
                    for v in vulns:
                        f.write(f"  {v['param']}\n")
            
            with open(results_filename, 'rb') as f:
                await update.message.reply_document(f)
            
            os.remove(results_filename)
        else:
            await update.message.reply_text("‚ùå –£—è–∑–≤–∏–º–æ—Å—Ç–µ–π –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
        
    except Exception as e:
        await update.message.reply_text(f"‚ùå –û—à–∏–±–∫–∞: {str(e)}")
    finally:
        if os.path.exists(filename):
            os.remove(filename)
        
        with sessions_lock:
            del user_sessions[user_id]

async def error_handler(update: Update, context: CallbackContext):
    logger.error(f"–û—à–∏–±–∫–∞: {context.error}", exc_info=True)

# ===================== –ó–ê–ü–£–°–ö =====================

def main():
    """–ó–∞–ø—É—Å–∫ –±–æ—Ç–∞"""
    try:
        print("üü¢ –°–æ–∑–¥–∞—é –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ...")
        sys.stdout.flush()
        
        # –°–û–ó–î–ê–ï–ú EVENT LOop –ü–†–ê–í–ò–õ–¨–ù–û
        try:
            loop = asyncio.get_running_loop()
        except RuntimeError:
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
        
        print(f"üü¢ Event loop —Å–æ–∑–¥–∞–Ω: {loop}")
        sys.stdout.flush()
        
        application = Application.builder().token(TOKEN).build()
        
        print("üü¢ –î–æ–±–∞–≤–ª—è—é –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∏...")
        sys.stdout.flush()
        
        application.add_handler(CommandHandler("start", start))
        application.add_handler(CommandHandler("help", help_command))
        application.add_handler(CommandHandler("search", search_command))
        application.add_handler(CommandHandler("scanurl", scanurl_command))
        application.add_handler(CommandHandler("scanlist", scanlist_command))
        
        application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))
        application.add_handler(MessageHandler(filters.Document.ALL, handle_file))
        
        application.add_error_handler(error_handler)
        
        print("üü¢ –ë–æ—Ç –≥–æ—Ç–æ–≤ –∫ –∑–∞–ø—É—Å–∫—É!")
        sys.stdout.flush()
        
        print("üü¢ –ó–∞–ø—É—Å–∫–∞—é polling...")
        sys.stdout.flush()
        
        # –ó–ê–ü–£–°–ö–ê–ï–ú –° –Ø–í–ù–´–ú LOOPOM
        application.run_polling()
        
    except Exception as e:
        logging.critical(f"üî• –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê –í MAIN: {e}")
        traceback.print_exc(file=sys.stdout)
        sys.stdout.flush()
        sys.exit(1)

if __name__ == "__main__":
    try:
        main()
    except Exception as e:
        logging.critical(f"üî• –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê –ü–†–ò –ó–ê–ü–£–°–ö–ï: {e}")
        traceback.print_exc(file=sys.stdout)
        sys.stdout.flush()
        sys.exit(1)



