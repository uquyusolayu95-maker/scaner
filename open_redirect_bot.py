#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import sys
import types
import logging
import traceback
import asyncio
import urllib.parse
import os
import requests
import time
import random
import re
import json
from urllib.parse import urlparse, quote_plus
from concurrent.futures import ThreadPoolExecutor, as_completed
from threading import Lock

# ===================== –ù–ê–°–¢–†–û–ô–ö–ê –õ–û–ì–û–í (–í–ê–ñ–ù–û!) =====================
logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    level=logging.INFO,
    stream=sys.stdout,
    force=True
)
sys.stdout.reconfigure(line_buffering=True)

# –ì–ª–æ–±–∞–ª—å–Ω—ã–π –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ –æ—à–∏–±–æ–∫
def global_exception_handler(exctype, value, tb):
    logging.critical("üî• –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê:", exc_info=(exctype, value, tb))
    sys.stdout.flush()
    sys.exit(1)

sys.excepthook = global_exception_handler

# ===================== –ó–ê–ì–õ–£–®–ö–ê –î–õ–Ø imghdr =====================
imghdr = types.ModuleType('imghdr')
def what(*args, **kwargs):
    return None
imghdr.what = what
sys.modules['imghdr'] = imghdr

# ===================== –ò–ú–ü–û–†–¢–´ –ë–ò–ë–õ–ò–û–¢–ï–ö TELEGRAM =====================
from telegram import Update
from telegram.constants import ParseMode
from telegram.ext import Application, CommandHandler, MessageHandler, CallbackContext
from telegram.ext import filters

# ===================== –ù–ê–°–¢–†–û–ô–ö–ò =====================
TOKEN = "8618230715:AAF30AK5Nef4KnLuILUXu7GKpKO4TLrHWYc"

USER_AGENTS = [
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36",
    "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36",
    "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36"
]

REDIRECT_PARAMS = [
    "redirect", "url", "next", "return", "returnTo", "return_to",
    "continue", "dest", "destination", "redir", "redirect_uri",
    "redirect_url", "goto", "target", "r", "u", "link", "to"
]

TEST_PAYLOAD = "https://example.com"

PAYLOADS = [
    TEST_PAYLOAD,
    f"//example.com",
    f"http://example.com",
    f"https:example.com",
    f"/\\example.com",
    f"https://example.com%2F%2E%2E",
    f"%2F%2Fexample.com",
    f"///example.com",
    f"https://example.com/?a=1&b=2",
    f"https://example.com#test",
]

user_sessions = {}
sessions_lock = Lock()
logger = logging.getLogger(__name__)

# ===================== –§–£–ù–ö–¶–ò–ò –ü–û–ò–°–ö–ê =====================

def search_domains_google(query="site:.com", max_pages=1):
    """–ò—â–µ—Ç –¥–æ–º–µ–Ω—ã —á–µ—Ä–µ–∑ Google (–æ–±—Ö–æ–¥ –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏)"""
    domains = set()
    
    # –†–æ—Ç–∞—Ü–∏—è User-Agent'–æ–≤
    user_agents = [
        "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
        "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.0 Safari/605.1.15",
        "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36",
        "Mozilla/5.0 (Windows NT 10.0; rv:109.0) Gecko/20100101 Firefox/121.0",
        "Mozilla/5.0 (iPhone; CPU iPhone OS 16_6 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/16.6 Mobile/15E148 Safari/604.1"
    ]
    
    headers = {
        "User-Agent": random.choice(user_agents),
        "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8",
        "Accept-Language": "en-US,en;q=0.9,ru;q=0.8",
        "Accept-Encoding": "gzip, deflate, br",
        "DNT": "1",
        "Connection": "keep-alive",
        "Upgrade-Insecure-Requests": "1",
        "Sec-Fetch-Dest": "document",
        "Sec-Fetch-Mode": "navigate",
        "Sec-Fetch-Site": "none",
        "Cache-Control": "max-age=0"
    }
    
    import urllib.parse
    
    # –ö–æ–¥–∏—Ä—É–µ–º –∑–∞–ø—Ä–æ—Å
    encoded_query = urllib.parse.quote_plus(query)
    
    for page in range(max_pages):
        start = page * 10
        url = f"https://www.google.com/search?q={encoded_query}&start={start}"
        
        try:
            print(f"[*] –ó–∞–ø—Ä–æ—Å –∫ Google: —Å—Ç—Ä–∞–Ω–∏—Ü–∞ {page+1}")
            sys.stdout.flush()
            
            session = requests.Session()
            session.headers.update(headers)
            
            # –î–æ–±–∞–≤–ª—è–µ–º –∫—É–∫–∏, —á—Ç–æ–±—ã –≤—ã–≥–ª—è–¥–µ—Ç—å –∫–∞–∫ —Ä–µ–∞–ª—å–Ω—ã–π –±—Ä–∞—É–∑–µ—Ä
            session.cookies.set('CONSENT', 'YES+', domain='.google.com')
            
            r = session.get(
                url, 
                timeout=15,
                allow_redirects=True
            )
            
            print(f"[*] –°—Ç–∞—Ç—É—Å –æ—Ç–≤–µ—Ç–∞: {r.status_code}")
            sys.stdout.flush()
            
            if r.status_code == 200:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ –∫–∞–ø—á–∞ –ª–∏ —ç—Ç–æ
                if 'captcha' in r.text.lower() or 'recaptcha' in r.text.lower():
                    print("[!] Google –∑–∞–ø—Ä–æ—Å–∏–ª –∫–∞–ø—á—É. –ü–µ—Ä–µ–∫–ª—é—á–∞—é—Å—å –Ω–∞ –∑–∞–ø–∞—Å–Ω–æ–π –ø–æ–∏—Å–∫–æ–≤–∏–∫.")
                    sys.stdout.flush()
                    return search_alternative(query)
                
                # –ò—â–µ–º —Å—Å—ã–ª–∫–∏ –≤ –Ω–æ—Ä–º–∞–ª—å–Ω–æ–º HTML
                found = re.findall(r'<a[^>]*href="https?://([^/"]+)[^"]*"[^>]*>', r.text)
                
                # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ —á–µ—Ä–µ–∑ href, –∏—â–µ–º –ø—Ä–æ—Å—Ç–æ —Å—Å—ã–ª–∫–∏ –≤ —Ç–µ–∫—Å—Ç–µ
                if not found:
                    found = re.findall(r'https?://([^/\s"\'<>]+)', r.text)
                
                for domain in found:
                    # –ß–∏—Å—Ç–∏–º –¥–æ–º–µ–Ω
                    domain = domain.split('/')[0].split('?')[0].split('#')[0]
                    
                    # –û—Ç—Å–µ–∏–≤–∞–µ–º –º—É—Å–æ—Ä Google
                    if ('.' in domain 
                        and not any(x in domain.lower() for x in [
                            'google', 'youtube', 'blogger', 'gstatic',
                            'googleapis', 'ytimg', 'ggpht', 'googleusercontent',
                            'google-analytics', 'googlesyndication', 'doubleclick'
                        ])
                        and len(domain) < 50
                        and domain.count('.') <= 3):
                        domains.add(domain)
                
                print(f"[*] –ù–∞–π–¥–µ–Ω–æ –¥–æ–º–µ–Ω–æ–≤ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ {page+1}: {len(domains)}")
                sys.stdout.flush()
                
                # –ï—Å–ª–∏ –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞—à–ª–∏, –ø—Ä–æ–±—É–µ–º –¥—Ä—É–≥–æ–π –º–µ—Ç–æ–¥
                if not domains:
                    print("[*] –ü—Ä–æ–±—É—é –¥—Ä—É–≥–æ–π –º–µ—Ç–æ–¥ –ø–∞—Ä—Å–∏–Ω–≥–∞...")
                    sys.stdout.flush()
                    # –ò—â–µ–º –≤ —Ü–∏—Ç–∞—Ç–∞—Ö
                    found = re.findall(r'>(https?://[^<]+)<', r.text)
                    for url in found:
                        if '://' in url:
                            domain = url.split('/')[2] if len(url.split('/')) > 2 else url
                            if '.' in domain and not any(x in domain for x in ['google']):
                                domains.add(domain)
            else:
                print(f"[!] Google –≤–µ—Ä–Ω—É–ª —Å—Ç–∞—Ç—É—Å {r.status_code}")
                sys.stdout.flush()
            
            # –ñ–¥—ë–º –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
            time.sleep(random.uniform(5, 8))
            
        except Exception as e:
            print(f"[!] –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ: {e}")
            sys.stdout.flush()
            continue
    
    # –ï—Å–ª–∏ –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞—à–ª–∏, –∏—Å–ø–æ–ª—å–∑—É–µ–º –∑–∞–ø–∞—Å–Ω–æ–π –ø–æ–∏—Å–∫–æ–≤–∏–∫
    if not domains:
        print("[*] Google –Ω–µ –¥–∞–ª —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤. –ü—Ä–æ–±—É—é Bing...")
        sys.stdout.flush()
        return search_bing(query)
    
    return list(domains)

def search_alternative(query):
    """–ü–æ–∏—Å–∫ —á–µ—Ä–µ–∑ DuckDuckGo (–∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞)"""
    domains = set()
    headers = {"User-Agent": random.choice(USER_AGENTS)}
    
    try:
        url = f"https://html.duckduckgo.com/html/?q={urllib.parse.quote_plus(query)}"
        r = requests.get(url, headers=headers, timeout=10)
        
        if r.status_code == 200:
            found = re.findall(r'https?://([^/\s"\'<>]+)', r.text)
            for domain in found:
                domain = domain.split('/')[0]
                if '.' in domain and not any(x in domain for x in ['duckduckgo']):
                    domains.add(domain)
        return list(domains)
    except:
        return []

def search_bing(query):
    """–ü–æ–∏—Å–∫ —á–µ—Ä–µ–∑ Bing"""
    domains = set()
    headers = {"User-Agent": random.choice(USER_AGENTS)}
    
    try:
        url = f"https://www.bing.com/search?q={urllib.parse.quote_plus(query)}"
        r = requests.get(url, headers=headers, timeout=10)
        
        if r.status_code == 200:
            found = re.findall(r'https?://([^/\s"\'<>]+)', r.text)
            for domain in found:
                domain = domain.split('/')[0]
                if '.' in domain and not any(x in domain for x in ['bing', 'microsoft']):
                    domains.add(domain)
        return list(domains)
    except:
        return []
# ===================== –§–£–ù–ö–¶–ò–ò –°–ö–ê–ù–ò–†–û–í–ê–ù–ò–Ø =====================

def check_open_redirect(url, param, payload):
    if '?' in url:
        separator = '&'
    else:
        separator = '?'
    
    test_url = f"{url}{separator}{param}={payload}"
    headers = {"User-Agent": random.choice(USER_AGENTS)}
    
    try:
        r = requests.get(test_url, headers=headers, timeout=8, allow_redirects=False)
        
        if 'Location' in r.headers:
            location = r.headers['Location']
            if 'example.com' in location or payload.replace('https://', '').replace('http://', '') in location:
                return {
                    "vulnerable": True,
                    "url": test_url,
                    "param": param,
                    "payload": payload,
                    "location": location,
                    "status": r.status_code
                }
        
        if 300 <= r.status_code < 400 and 'example.com' in r.text.lower():
            return {
                "vulnerable": True,
                "url": test_url,
                "param": param,
                "payload": payload,
                "status": r.status_code,
                "type": "meta/html"
            }
        
        return None
    except Exception as e:
        logger.debug(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ {test_url}: {e}")
        return None

def scan_single_url(url):
    results = []
    for param in REDIRECT_PARAMS:
        for payload in PAYLOADS:
            result = check_open_redirect(url, param, payload)
            if result:
                results.append(result)
    return results

def scan_urls(urls, max_workers=5, progress_callback=None):
    all_results = {}
    total = len(urls)
    completed = 0
    
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        future_to_url = {executor.submit(scan_single_url, url): url for url in urls}
        
        for future in as_completed(future_to_url):
            url = future_to_url[future]
            completed += 1
            if progress_callback:
                progress_callback(completed, total)
            
            try:
                results = future.result()
                if results:
                    all_results[url] = results
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–∏ {url}: {e}")
                continue
    
    return all_results

# ===================== –û–ë–†–ê–ë–û–¢–ß–ò–ö–ò –ö–û–ú–ê–ù–î =====================

async def start(update: Update, context: CallbackContext):
    user = update.effective_user
    await update.message.reply_text(
        f"–ü—Ä–∏–≤–µ—Ç, {user.first_name}!\n\n"
        "–Ø –±–æ—Ç –¥–ª—è –ø–æ–∏—Å–∫–∞ Open Redirect —É—è–∑–≤–∏–º–æ—Å—Ç–µ–π.\n\n"
        "–ö–æ–º–∞–Ω–¥—ã:\n"
        "/search - –ù–∞–π—Ç–∏ –¥–æ–º–µ–Ω—ã –∏ –ø—Ä–æ—Å–∫–∞–Ω–∏—Ä–æ–≤–∞—Ç—å\n"
        "/scanurl - –°–∫–∞–Ω–∏—Ä–æ–≤–∞—Ç—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π URL\n"
        "/scanlist - –°–∫–∞–Ω–∏—Ä–æ–≤–∞—Ç—å —Å–ø–∏—Å–æ–∫ URL –∏–∑ —Ñ–∞–π–ª–∞\n"
        "/help - –ü–æ–¥—Ä–æ–±–Ω–∞—è –ø–æ–º–æ—â—å"
    )

async def help_command(update: Update, context: CallbackContext):
    help_text = """
*Open Redirect Bot - –ü–æ–º–æ—â—å*

/search - –ù–∞–π—Ç–∏ –¥–æ–º–µ–Ω—ã –∏ –ø—Ä–æ—Å–∫–∞–Ω–∏—Ä–æ–≤–∞—Ç—å
/scanurl - –°–∫–∞–Ω–∏—Ä–æ–≤–∞—Ç—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π URL
/scanlist - –°–∫–∞–Ω–∏—Ä–æ–≤–∞—Ç—å —Å–ø–∏—Å–æ–∫ URL –∏–∑ —Ñ–∞–π–ª–∞
"""
    await update.message.reply_text(help_text, parse_mode=ParseMode.MARKDOWN)

async def search_command(update: Update, context: CallbackContext):
    user_id = update.effective_user.id
    
    with sessions_lock:
        user_sessions[user_id] = {
            'state': 'awaiting_search_query',
            'data': {}
        }
    
    await update.message.reply_text(
        "–í–≤–µ–¥–∏—Ç–µ –ø–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å –¥–ª—è Google\n"
        "–ò–ª–∏ –æ—Ç–ø—Ä–∞–≤—å—Ç–µ 'default' –¥–ª—è –ø–æ–∏—Å–∫–∞ site:.com"
    )

async def scanurl_command(update: Update, context: CallbackContext):
    user_id = update.effective_user.id
    
    with sessions_lock:
        user_sessions[user_id] = {
            'state': 'awaiting_url',
            'data': {}
        }
    
    await update.message.reply_text(
        "–û—Ç–ø—Ä–∞–≤—å—Ç–µ URL –¥–ª—è —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è"
    )

async def scanlist_command(update: Update, context: CallbackContext):
    user_id = update.effective_user.id
    
    with sessions_lock:
        user_sessions[user_id] = {
            'state': 'awaiting_file',
            'data': {}
        }
    
    await update.message.reply_text(
        "–û—Ç–ø—Ä–∞–≤—å—Ç–µ —Ç–µ–∫—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª —Å URL (–ø–æ –æ–¥–Ω–æ–º—É –Ω–∞ —Å—Ç—Ä–æ–∫—É)"
    )

async def handle_message(update: Update, context: CallbackContext):
    user_id = update.effective_user.id
    text = update.message.text
    
    with sessions_lock:
        session = user_sessions.get(user_id)
        if not session:
            await update.message.reply_text("–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ /start")
            return
    
    state = session.get('state')
    
    if state == 'awaiting_search_query':
        query = text if text != 'default' else 'site:.com'
        
        await update.message.reply_text(f"üîç –ò—â—É –¥–æ–º–µ–Ω—ã...")
        
        try:
            domains = search_domains_google(query, max_pages=2)
            
            if not domains:
                await update.message.reply_text("‚ùå –î–æ–º–µ–Ω—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
                return
            
            urls = []
            for domain in domains[:20]:
                urls.extend(generate_urls_from_domain(domain))
            
            await update.message.reply_text(f"üîç –°–∫–∞–Ω–∏—Ä—É—é {len(urls)} URL...")
            
            def progress(current, total):
                if current % 50 == 0:
                    context.application.create_task(
                        update.message.reply_text(f"–ü—Ä–æ–≥—Ä–µ—Å—Å: {current}/{total}")
                    )
            
            results = scan_urls(urls, max_workers=5, progress_callback=progress)
            
            if results:
                msg = f"‚úÖ –ù–∞–π–¥–µ–Ω–æ —É—è–∑–≤–∏–º–æ—Å—Ç–µ–π –Ω–∞ {len(results)} URL"
                await update.message.reply_text(msg)
                
                filename = f"results_{user_id}.txt"
                with open(filename, 'w') as f:
                    for url, vulns in results.items():
                        f.write(f"\n[VULN] {url}\n")
                        for v in vulns:
                            f.write(f"  {v['param']}\n")
                
                with open(filename, 'rb') as f:
                    await update.message.reply_document(f)
                
                os.remove(filename)
            else:
                await update.message.reply_text("‚ùå –£—è–∑–≤–∏–º–æ—Å—Ç–µ–π –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
            
        except Exception as e:
            await update.message.reply_text(f"‚ùå –û—à–∏–±–∫–∞: {str(e)}")
            logger.error(f"–û—à–∏–±–∫–∞: {e}", exc_info=True)
        
        with sessions_lock:
            del user_sessions[user_id]
    
    elif state == 'awaiting_url':
        url = text
        if not url.startswith(('http://', 'https://')):
            url = 'https://' + url
        
        await update.message.reply_text(f"üîç –°–∫–∞–Ω–∏—Ä—É—é...")
        
        try:
            results = scan_single_url(url)
            
            if results:
                msg = f"‚úÖ –ù–∞–π–¥–µ–Ω–æ —É—è–∑–≤–∏–º–æ—Å—Ç–µ–π: {len(results)}"
                await update.message.reply_text(msg)
            else:
                await update.message.reply_text("‚ùå –£—è–∑–≤–∏–º–æ—Å—Ç–µ–π –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
            
        except Exception as e:
            await update.message.reply_text(f"‚ùå –û—à–∏–±–∫–∞: {str(e)}")
        
        with sessions_lock:
            del user_sessions[user_id]

async def handle_file(update: Update, context: CallbackContext):
    user_id = update.effective_user.id
    
    with sessions_lock:
        session = user_sessions.get(user_id)
        if not session or session.get('state') != 'awaiting_file':
            await update.message.reply_text("–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ /scanlist")
            return
    
    file = update.message.document
    if not file.file_name.endswith('.txt'):
        await update.message.reply_text("‚ùå –ù—É–∂–µ–Ω .txt —Ñ–∞–π–ª")
        return
    
    await update.message.reply_text("üì• –ó–∞–≥—Ä—É–∂–∞—é...")
    
    file_obj = await file.get_file()
    filename = f"upload_{user_id}.txt"
    await file_obj.download_to_drive(filename)
    
    try:
        with open(filename, 'r') as f:
            urls = [line.strip() for line in f if line.strip()]
        
        if not urls:
            await update.message.reply_text("‚ùå –§–∞–π–ª –ø—É—Å—Ç")
            return
        
        urls = [u if u.startswith(('http://', 'https://')) else 'https://' + u for u in urls]
        
        await update.message.reply_text(f"üîç –°–∫–∞–Ω–∏—Ä—É—é {len(urls)} URL...")
        
        def progress(current, total):
            if current % 20 == 0:
                context.application.create_task(
                    update.message.reply_text(f"–ü—Ä–æ–≥—Ä–µ—Å—Å: {current}/{total}")
                )
        
        results = scan_urls(urls, max_workers=5, progress_callback=progress)
        
        if results:
            msg = f"‚úÖ –ù–∞–π–¥–µ–Ω–æ —É—è–∑–≤–∏–º–æ—Å—Ç–µ–π –Ω–∞ {len(results)} URL"
            await update.message.reply_text(msg)
            
            results_filename = f"results_{user_id}.txt"
            with open(results_filename, 'w') as f:
                for url, vulns in results.items():
                    f.write(f"\n[VULN] {url}\n")
                    for v in vulns:
                        f.write(f"  {v['param']}\n")
            
            with open(results_filename, 'rb') as f:
                await update.message.reply_document(f)
            
            os.remove(results_filename)
        else:
            await update.message.reply_text("‚ùå –£—è–∑–≤–∏–º–æ—Å—Ç–µ–π –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
        
    except Exception as e:
        await update.message.reply_text(f"‚ùå –û—à–∏–±–∫–∞: {str(e)}")
    finally:
        if os.path.exists(filename):
            os.remove(filename)
        
        with sessions_lock:
            del user_sessions[user_id]

async def error_handler(update: Update, context: CallbackContext):
    logger.error(f"–û—à–∏–±–∫–∞: {context.error}", exc_info=True)

# ===================== –ó–ê–ü–£–°–ö =====================

def main():
    """–ó–∞–ø—É—Å–∫ –±–æ—Ç–∞"""
    try:
        print("üü¢ –°–æ–∑–¥–∞—é –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ...")
        sys.stdout.flush()
        
        # –°–û–ó–î–ê–ï–ú EVENT LOop –ü–†–ê–í–ò–õ–¨–ù–û
        try:
            loop = asyncio.get_running_loop()
        except RuntimeError:
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
        
        print(f"üü¢ Event loop —Å–æ–∑–¥–∞–Ω: {loop}")
        sys.stdout.flush()
        
        application = Application.builder().token(TOKEN).build()
        
        print("üü¢ –î–æ–±–∞–≤–ª—è—é –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∏...")
        sys.stdout.flush()
        
        application.add_handler(CommandHandler("start", start))
        application.add_handler(CommandHandler("help", help_command))
        application.add_handler(CommandHandler("search", search_command))
        application.add_handler(CommandHandler("scanurl", scanurl_command))
        application.add_handler(CommandHandler("scanlist", scanlist_command))
        
        application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))
        application.add_handler(MessageHandler(filters.Document.ALL, handle_file))
        
        application.add_error_handler(error_handler)
        
        print("üü¢ –ë–æ—Ç –≥–æ—Ç–æ–≤ –∫ –∑–∞–ø—É—Å–∫—É!")
        sys.stdout.flush()
        
        print("üü¢ –ó–∞–ø—É—Å–∫–∞—é polling...")
        sys.stdout.flush()
        
        # –ó–ê–ü–£–°–ö–ê–ï–ú –° –Ø–í–ù–´–ú LOOPOM
        application.run_polling()
        
    except Exception as e:
        logging.critical(f"üî• –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê –í MAIN: {e}")
        traceback.print_exc(file=sys.stdout)
        sys.stdout.flush()
        sys.exit(1)

if __name__ == "__main__":
    try:
        main()
    except Exception as e:
        logging.critical(f"üî• –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê –ü–†–ò –ó–ê–ü–£–°–ö–ï: {e}")
        traceback.print_exc(file=sys.stdout)
        sys.stdout.flush()
        sys.exit(1)




